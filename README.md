# ğŸ¶ SynthStep

> â€œDonâ€™t dance to the music â€” *make the music dance to you.*â€

---

## ğŸŒŸ Inspiration
For our **ShellHacks 2025** project, we were inspired by the idea of learning and making music in a more **interactive and playful** way.  
Instead of dancing *to* music, we wanted to **reverse the roles**, letting music be **created as you dance**.  
Our goal was to capture the fun of experimentation and make music feel natural, intuitive, and expressive.

---

## ğŸ§ What It Does
**SynthStep** is an interactive **loop station** that turns **hand and body movements** into music.  

ğŸµ **Features**
- Real-time **motion-to-sound** mapping using your camera  
- Play multiple instruments: drums, synths, and strings  
- Adjust **pitch** and **volume** with sliders  
- A **Freeflow mode** for a completely hands-free creative experience to just *flow*

![UI Placeholder](./assets/interface.png)

---

## ğŸ› ï¸ How We Built It
We built SynthStep with a combination of **web technologies** and **machine learning tools**:

- **React + Vite** â†’ Frontend interface and UI components  
- **Tone.js** â†’ Real-time sound synthesis and looping  
- **TensorFlow PoseDetection** â†’ Camera-based body tracking  

We mapped detected movement to sound settings like instrument type, pitch, and rhythm. Transforming simple gestures into live musical performances.

---

## ğŸ§© Challenges We Faced
- Getting **movement detection** and **sound timing** to sync naturally for an intuitive feel
- Implementing **audio recording and loop layering** in the browser  
- Learning **music theory concepts** on the fly, which was ambitious for a 36-hour hackathon!  

---

## ğŸ† Accomplishments
- Created a **working prototype** that lets users make music with movement  
- Designed a clean, reactive **UI** for quick interaction  
- Integrated **real-time sound** and **camera-based tracking** for intuitive play  
- Showcased a **hands-free Freeflow mode** where users can â€œdance to createâ€

---

## ğŸ“š What We Learned
- Real-time **sound synthesis** and **gesture mapping**  
- Importance of **timing and latency** in interactive music projects  
- Balancing **creativity with technical complexity** under hackathon pressure  

---

## ğŸš€ Whatâ€™s Next
- Finalize **looping and recording** features to layer full songs  
- **Refine motion tracking** using a **hand tracker** to interpret signals and gestures, not just wrist movements  
- Add **more instruments and effects** for more creative control  
- Expand **Freeflow mode** to interpret entire **dance sequences**  
- Evolve SynthStep into an **interactive music game** or creative tool for everyone ğŸ®ğŸµ

---

## ğŸ‘¥ Team
Built with â¤ï¸ at **ShellHacks 2025** by  
**Diego Pedroza** and **Rebecca Osorio**

---